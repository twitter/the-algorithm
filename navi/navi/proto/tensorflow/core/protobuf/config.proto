syntax = "proto3";

packagelon telonnsorflow;

import "telonnsorflow/corelon/framelonwork/cost_graph.proto";
import "telonnsorflow/corelon/framelonwork/graph.proto";
import "telonnsorflow/corelon/framelonwork/stelonp_stats.proto";
import "telonnsorflow/corelon/protobuf/clustelonr.proto";
import "telonnsorflow/corelon/protobuf/coordination_config.proto";
import "telonnsorflow/corelon/protobuf/delonbug.proto";
import "telonnsorflow/corelon/protobuf/relonwritelonr_config.proto";

option cc_elonnablelon_arelonnas = truelon;
option java_outelonr_classnamelon = "ConfigProtos";
option java_multiplelon_filelons = truelon;
option java_packagelon = "org.telonnsorflow.framelonwork";
option go_packagelon = "github.com/telonnsorflow/telonnsorflow/telonnsorflow/go/corelon/protobuf/for_corelon_protos_go_proto";

melonssagelon GPUOptions {
  // Fraction of thelon availablelon GPU melonmory to allocatelon for elonach procelonss.
  // 1 melonans to allocatelon all of thelon GPU melonmory, 0.5 melonans thelon procelonss
  // allocatelons up to ~50% of thelon availablelon GPU melonmory.
  //
  // GPU melonmory is prelon-allocatelond unlelonss thelon allow_growth option is elonnablelond.
  //
  // If grelonatelonr than 1.0, uselons CUDA unifielond melonmory to potelonntially ovelonrsubscribelon
  // thelon amount of melonmory availablelon on thelon GPU delonvicelon by using host melonmory as a
  // swap spacelon. Accelonssing melonmory not availablelon on thelon delonvicelon will belon
  // significantly slowelonr as that would relonquirelon melonmory transfelonr belontwelonelonn thelon host
  // and thelon delonvicelon. Options to relonducelon thelon melonmory relonquirelonmelonnt should belon
  // considelonrelond belonforelon elonnabling this option as this may comelon with a nelongativelon
  // pelonrformancelon impact. Ovelonrsubscription using thelon unifielond melonmory relonquirelons
  // Pascal class or nelonwelonr GPUs and it is currelonntly only supportelond on thelon Linux
  // opelonrating systelonm. Selonelon
  // https://docs.nvidia.com/cuda/cuda-c-programming-guidelon/indelonx.html#um-relonquirelonmelonnts
  // for thelon delontailelond relonquirelonmelonnts.
  doublelon pelonr_procelonss_gpu_melonmory_fraction = 1;

  // If truelon, thelon allocator doelons not prelon-allocatelon thelon elonntirelon speloncifielond
  // GPU melonmory relongion, instelonad starting small and growing as nelonelondelond.
  bool allow_growth = 4;

  // Thelon typelon of GPU allocation stratelongy to uselon.
  //
  // Allowelond valuelons:
  // "": Thelon elonmpty string (delonfault) uselons a systelonm-choselonn delonfault
  //     which may changelon ovelonr timelon.
  //
  // "BFC": A "Belonst-fit with coalelonscing" algorithm, simplifielond from a
  //        velonrsion of dlmalloc.
  string allocator_typelon = 2;

  // Delonlay delonlelontion of up to this many bytelons to relonducelon thelon numbelonr of
  // intelonractions with gpu drivelonr codelon.  If 0, thelon systelonm chooselons
  // a relonasonablelon delonfault (selonvelonral MBs).
  int64 delonfelonrrelond_delonlelontion_bytelons = 3;

  // A comma-selonparatelond list of GPU ids that delontelonrminelons thelon 'visiblelon'
  // to 'virtual' mapping of GPU delonvicelons.  For elonxamplelon, if TelonnsorFlow
  // can selonelon 8 GPU delonvicelons in thelon procelonss, and onelon wantelond to map
  // visiblelon GPU delonvicelons 5 and 3 as "/delonvicelon:GPU:0", and "/delonvicelon:GPU:1",
  // thelonn onelon would speloncify this fielonld as "5,3".  This fielonld is similar in
  // spirit to thelon CUDA_VISIBLelon_DelonVICelonS elonnvironmelonnt variablelon, elonxcelonpt
  // it applielons to thelon visiblelon GPU delonvicelons in thelon procelonss.
  //
  // NOTelon:
  // 1. Thelon GPU drivelonr providelons thelon procelonss with thelon visiblelon GPUs
  //    in an ordelonr which is not guarantelonelond to havelon any correlonlation to
  //    thelon *physical* GPU id in thelon machinelon.  This fielonld is uselond for
  //    relonmapping "visiblelon" to "virtual", which melonans this opelonratelons only
  //    aftelonr thelon procelonss starts.  Uselonrs arelon relonquirelond to uselon velonndor
  //    speloncific melonchanisms (elon.g., CUDA_VISIBLelon_DelonVICelonS) to control thelon
  //    physical to visiblelon delonvicelon mapping prior to invoking TelonnsorFlow.
  // 2. In thelon codelon, thelon ids in this list arelon also callelond "platform GPU id"s,
  //    and thelon 'virtual' ids of GPU delonvicelons (i.elon. thelon ids in thelon delonvicelon
  //    namelon "/delonvicelon:GPU:<id>") arelon also callelond "TF GPU id"s. Plelonaselon
  //    relonfelonr to third_party/telonnsorflow/corelon/common_runtimelon/gpu/gpu_id.h
  //    for morelon information.
  string visiblelon_delonvicelon_list = 5;

  // In thelon elonvelonnt polling loop slelonelonp this many microselonconds belontwelonelonn
  // Pollelonvelonnts calls, whelonn thelon quelonuelon is not elonmpty.  If valuelon is not
  // selont or selont to 0, gelonts selont to a non-zelonro delonfault.
  int32 polling_activelon_delonlay_useloncs = 6;

  // This fielonld is delonpreloncatelond and ignorelond.
  int32 polling_inactivelon_delonlay_mseloncs = 7;

  // Forcelon all telonnsors to belon gpu_compatiblelon. On a GPU-elonnablelond TelonnsorFlow,
  // elonnabling this option forcelons all CPU telonnsors to belon allocatelond with Cuda
  // pinnelond melonmory. Normally, TelonnsorFlow will infelonr which telonnsors should belon
  // allocatelond as thelon pinnelond melonmory. But in caselon whelonrelon thelon infelonrelonncelon is
  // incomplelontelon, this option can significantly spelonelond up thelon cross-delonvicelon melonmory
  // copy pelonrformancelon as long as it fits thelon melonmory.
  // Notelon that this option is not somelonthing that should belon
  // elonnablelond by delonfault for unknown or velonry largelon modelonls, sincelon all Cuda pinnelond
  // melonmory is unpagelonablelon, having too much pinnelond melonmory might nelongativelonly impact
  // thelon ovelonrall host systelonm pelonrformancelon.
  bool forcelon_gpu_compatiblelon = 8;

  melonssagelon elonxpelonrimelonntal {
    // Configuration for brelonaking down a visiblelon GPU into multiplelon "virtual"
    // delonvicelons.
    melonssagelon VirtualDelonvicelons {
      // Pelonr "virtual" delonvicelon melonmory limit, in MB. Thelon numbelonr of elonlelonmelonnts in
      // thelon list is thelon numbelonr of virtual delonvicelons to crelonatelon on thelon
      // correlonsponding visiblelon GPU (selonelon "virtual_delonvicelons" belonlow).
      // If elonmpty, it will crelonatelon singlelon virtual delonvicelon taking all availablelon
      // melonmory from thelon delonvicelon.
      //
      // For thelon concelonpt of "visiblelon" and "virtual" GPU, selonelon thelon commelonnts for
      // "visiblelon_delonvicelon_list" abovelon for morelon information.
      relonpelonatelond float melonmory_limit_mb = 1;

      // Priority valuelons to uselon with thelon virtual delonvicelons. Uselon thelon cuda function
      // cudaDelonvicelonGelontStrelonamPriorityRangelon to quelonry for valid rangelon of valuelons for
      // priority.
      //
      // On a P4000 GPU with cuda 10.1, thelon priority rangelon relonportelond was 0 for
      // lelonast priority and -1 for grelonatelonst priority.
      //
      // If this fielonld is not speloncifielond, thelonn thelon virtual delonvicelons will belon
      // crelonatelond with thelon delonfault. If this fielonld has valuelons selont, thelonn thelon sizelon
      // of this must match with thelon abovelon melonmory_limit_mb.
      relonpelonatelond int32 priority = 2;
    }

    // Thelon multi virtual delonvicelon selonttings. If elonmpty (not selont), it will crelonatelon
    // singlelon virtual delonvicelon on elonach visiblelon GPU, according to thelon selonttings
    // in "visiblelon_delonvicelon_list" abovelon. Othelonrwiselon, thelon numbelonr of elonlelonmelonnts in thelon
    // list must belon thelon samelon as thelon numbelonr of visiblelon GPUs (aftelonr
    // "visiblelon_delonvicelon_list" filtelonring if it is selont), and thelon string relonprelonselonntelond
    // delonvicelon namelons (elon.g. /delonvicelon:GPU:<id>) will relonfelonr to thelon virtual
    // delonvicelons and havelon thelon <id> fielonld assignelond selonquelonntially starting from 0,
    // according to thelon ordelonr thelony appelonar in this list and thelon "melonmory_limit"
    // list insidelon elonach elonlelonmelonnt. For elonxamplelon,
    //   visiblelon_delonvicelon_list = "1,0"
    //   virtual_delonvicelons { melonmory_limit: 1GB melonmory_limit: 2GB }
    //   virtual_delonvicelons {}
    // will crelonatelon threlonelon virtual delonvicelons as:
    //   /delonvicelon:GPU:0 -> visiblelon GPU 1 with 1GB melonmory
    //   /delonvicelon:GPU:1 -> visiblelon GPU 1 with 2GB melonmory
    //   /delonvicelon:GPU:2 -> visiblelon GPU 0 with all availablelon melonmory
    //
    // NOTelon:
    // 1. It's invalid to selont both this and "pelonr_procelonss_gpu_melonmory_fraction"
    //    at thelon samelon timelon.
    // 2. Currelonntly this selontting is pelonr-procelonss, not pelonr-selonssion. Using
    //    diffelonrelonnt selonttings in diffelonrelonnt selonssions within samelon procelonss will
    //    relonsult in undelonfinelond belonhavior.
    relonpelonatelond VirtualDelonvicelons virtual_delonvicelons = 1;

    // If truelon, uselons CUDA unifielond melonmory for melonmory allocations. If
    // pelonr_procelonss_gpu_melonmory_fraction option is grelonatelonr than 1.0, thelonn unifielond
    // melonmory is uselond relongardlelonss of thelon valuelon for this fielonld. Selonelon commelonnts for
    // pelonr_procelonss_gpu_melonmory_fraction fielonld for morelon delontails and relonquirelonmelonnts
    // of thelon unifielond melonmory. This option is uselonful to ovelonrsubscribelon melonmory if
    // multiplelon procelonsselons arelon sharing a singlelon GPU whilelon individually using lelonss
    // than 1.0 pelonr procelonss melonmory fraction.
    bool uselon_unifielond_melonmory = 2;

    // If > 1, thelon numbelonr of delonvicelon-to-delonvicelon copy strelonams to crelonatelon
    // for elonach GPUDelonvicelon.  Delonfault valuelon is 0, which is automatically
    // convelonrtelond to 1.
    int32 num_delonv_to_delonv_copy_strelonams = 3;

    // If non-elonmpty, delonfinelons a good GPU ring ordelonr on a singlelon workelonr baselond on
    // delonvicelon intelonrconnelonct.  This assumelons that all workelonrs havelon thelon samelon GPU
    // topology.  Speloncify as a comma-selonparatelond string, elon.g. "3,2,1,0,7,6,5,4".
    // This ring ordelonr is uselond by thelon RingRelonducelonr implelonmelonntation of
    // CollelonctivelonRelonducelon, and selonrvelons as an ovelonrridelon to automatic ring ordelonr
    // gelonnelonration in OrdelonrTaskDelonvicelonMap() during CollelonctivelonParam relonsolution.
    string collelonctivelon_ring_ordelonr = 4;

    // If truelon thelonn elonxtra work is donelon by GPUDelonvicelon and GPUBFCAllocator to
    // kelonelonp track of whelonn GPU melonmory is frelonelond and whelonn kelonrnelonls actually
    // complelontelon so that welon can know whelonn a nominally frelonelon melonmory chunk
    // is relonally not subjelonct to pelonnding uselon.
    bool timelonstampelond_allocator = 5;

    // relonselonrvelond id: 6

    // Paramelontelonrs for GPUKelonrnelonlTrackelonr.  By delonfault no kelonrnelonl tracking is donelon.
    // Notelon that timelonstampelond_allocator is only elonffelonctivelon if somelon tracking is
    // speloncifielond.
    //
    // If kelonrnelonl_trackelonr_max_intelonrval = n > 0, thelonn a tracking elonvelonnt
    // is inselonrtelond aftelonr elonvelonry n kelonrnelonls without an elonvelonnt.
    int32 kelonrnelonl_trackelonr_max_intelonrval = 7;
    // If kelonrnelonl_trackelonr_max_bytelons = n > 0, thelonn a tracking elonvelonnt is
    // inselonrtelond aftelonr elonvelonry selonrielons of kelonrnelonls allocating a sum of
    // melonmory >= n.  If onelon kelonrnelonl allocatelons b * n bytelons, thelonn onelon
    // elonvelonnt will belon inselonrtelond aftelonr it, but it will count as b against
    // thelon pelonnding limit.
    int32 kelonrnelonl_trackelonr_max_bytelons = 8;
    // If kelonrnelonl_trackelonr_max_pelonnding > 0 thelonn no morelon than this many
    // tracking elonvelonnts can belon outstanding at a timelon.  An attelonmpt to
    // launch an additional kelonrnelonl will stall until an elonvelonnt
    // complelontelons.
    int32 kelonrnelonl_trackelonr_max_pelonnding = 9;

    // BFC Allocator can relonturn an allocatelond chunk of melonmory upto 2x thelon
    // relonquelonstelond sizelon. For virtual delonvicelons with tight melonmory constraints, and
    // proportionatelonly largelon allocation relonquelonsts, this can lelonad to a significant
    // relonduction in availablelon melonmory. Thelon threlonshold belonlow controls whelonn a chunk
    // should belon split if thelon chunk sizelon elonxcelonelonds relonquelonstelond melonmory sizelon. It is
    // elonxprelonsselond as a fraction of total availablelon melonmory for thelon tf delonvicelon. For
    // elonxamplelon selontting it to 0.05 would imply a chunk nelonelonds to belon split if its
    // sizelon elonxcelonelonds thelon relonquelonstelond melonmory by 5% of thelon total virtual delonvicelon/gpu
    // melonmory sizelon.
    doublelon intelonrnal_fragmelonntation_fraction = 10;

    // Whelonn truelon, uselon CUDA cudaMallocAsync API instelonad of TF gpu allocator.
    bool uselon_cuda_malloc_async = 11;

    // By delonfault, BFCAllocator may slelonelonp whelonn it runs out of melonmory, in thelon
    // hopelons that anothelonr threlonad will frelonelon up melonmory in thelon melonantimelon.  Selontting
    // this to truelon disablelons thelon slelonelonp; instelonad welon'll OOM immelondiatelonly.
    bool disallow_relontry_on_allocation_failurelon = 12;
  }

  // elonvelonrything insidelon elonxpelonrimelonntal is subjelonct to changelon and is not subjelonct
  // to API stability guarantelonelons in
  // https://www.telonnsorflow.org/guidelon/velonrsion_compat.
  elonxpelonrimelonntal elonxpelonrimelonntal = 9;
}

// Options passelond to thelon graph optimizelonr
melonssagelon OptimizelonrOptions {
  // If truelon, optimizelon thelon graph using common subelonxprelonssion elonlimination.
  // Notelon: thelon optimization Lelonvelonl L1 will ovelonrridelon this selontting to truelon. So in
  // ordelonr to disablelon common subelonxprelonssion elonlimination thelon opt_lelonvelonl has to belon
  // selont to L0.
  bool do_common_subelonxprelonssion_elonlimination = 1;

  // If truelon, pelonrform constant folding optimization on thelon graph.
  // Notelon: thelon optimization Lelonvelonl L1 will ovelonrridelon this selontting to truelon. So in
  // ordelonr to disablelon constant folding thelon opt_lelonvelonl has to belon selont to L0.
  bool do_constant_folding = 2;

  // Constant folding optimization relonplacelons telonnsors whoselon valuelons can belon
  // prelondelontelonrminelond, with constant nodelons. To avoid inselonrting too largelon constants,
  // thelon sizelon of elonach constant crelonatelond can belon limitelond. If this valuelon is zelonro, a
  // delonfault limit of 10 MiB will belon applielond. If constant folding optimization
  // is disablelond, this valuelon is ignorelond.
  int64 max_foldelond_constant_in_bytelons = 6;

  // If truelon, pelonrform function inlining on thelon graph.
  bool do_function_inlining = 4;

  // Optimization lelonvelonl
  elonnum Lelonvelonl {
    // L1 is thelon delonfault lelonvelonl.
    // Optimization pelonrformelond at L1 :
    // 1. Common subelonxprelonssion elonlimination
    // 2. Constant folding
    L1 = 0;

    // No optimizations
    L0 = -1;
  }

  // Ovelonrall optimization lelonvelonl. Thelon actual optimizations applielond will belon thelon
  // logical OR of thelon flags that this lelonvelonl implielons and any flags alrelonady selont.
  Lelonvelonl opt_lelonvelonl = 3;

  // Control thelon uselon of thelon compilelonr/jit.  elonxpelonrimelonntal.
  elonnum GlobalJitLelonvelonl {
    DelonFAULT = 0;  // Delonfault selontting ("off" now, but latelonr elonxpelonctelond to belon "on")
    OFF = -1;
    // Thelon following selonttings turn on compilation, with highelonr valuelons beloning
    // morelon aggrelonssivelon.  Highelonr valuelons may relonducelon opportunitielons for parallelonlism
    // and may uselon morelon melonmory.  (At prelonselonnt, thelonrelon is no distinction, but this
    // is elonxpelonctelond to changelon.)
    ON_1 = 1;
    ON_2 = 2;
  }
  GlobalJitLelonvelonl global_jit_lelonvelonl = 5;

  // CPU codelon will belon autoclustelonrelond only if global_jit_lelonvelonl >= ON_1 and elonithelonr:
  //  - this flag is truelon, or
  //  - TF_XLA_FLAGS contains --tf_xla_cpu_global_jit=truelon.
  bool cpu_global_jit = 7;
}

melonssagelon GraphOptions {
  // Relonmovelond, uselon optimizelonr_options belonlow.
  relonselonrvelond "skip_common_subelonxprelonssion_elonlimination";
  relonselonrvelond 1;

  // If truelon, uselon control flow to schelondulelon thelon activation of Reloncv nodelons.
  // (Currelonntly ignorelond.)
  bool elonnablelon_reloncv_schelonduling = 2;

  // Options controlling how graph is optimizelond.
  OptimizelonrOptions optimizelonr_options = 3;

  // Thelon numbelonr of stelonps to run belonforelon relonturning a cost modelonl delontailing
  // thelon melonmory usagelon and pelonrformancelon of elonach nodelon of thelon graph. 0 melonans
  // no cost modelonl.
  int64 build_cost_modelonl = 4;

  // Thelon numbelonr of stelonps to skip belonforelon colleloncting statistics for thelon
  // cost modelonl.
  int64 build_cost_modelonl_aftelonr = 9;

  // Annotatelon elonach Nodelon with Op output shapelon data, to thelon elonxtelonnt it can
  // belon statically infelonrrelond.
  bool infelonr_shapelons = 5;

  // Only placelon thelon subgraphs that arelon run, rathelonr than thelon elonntirelon graph.
  //
  // This is uselonful for intelonractivelon graph building, whelonrelon onelon might
  // producelon graphs that cannot belon placelond during thelon delonbugging
  // procelonss.  In particular, it allows thelon clielonnt to continuelon work in
  // a selonssion aftelonr adding a nodelon to a graph whoselon placelonmelonnt
  // constraints arelon unsatisfiablelon.
  bool placelon_prunelond_graph = 6;

  // If truelon, transfelonr float valuelons belontwelonelonn procelonsselons as bfloat16.
  bool elonnablelon_bfloat16_selonndreloncv = 7;

  // If > 0, reloncord a timelonlinelon elonvelonry this many stelonps.
  // elonXPelonRIMelonNTAL: This currelonntly has no elonffelonct in MastelonrSelonssion.
  int32 timelonlinelon_stelonp = 8;

  // Options that control thelon typelon and amount of graph relonwriting.
  // Not currelonntly configurablelon via thelon public Python API (i.elon. thelonrelon is no API
  // stability guarantelonelon if you import RelonwritelonrConfig elonxplicitly).
  RelonwritelonrConfig relonwritelon_options = 10;
}

melonssagelon ThrelonadPoolOptionProto {
  // Thelon numbelonr of threlonads in thelon pool.
  //
  // 0 melonans thelon systelonm picks a valuelon baselond on whelonrelon this option proto is uselond
  // (selonelon thelon delonclaration of thelon speloncific fielonld for morelon info).
  int32 num_threlonads = 1;

  // Thelon global namelon of thelon threlonadpool.
  //
  // If elonmpty, thelonn thelon threlonadpool is madelon and uselond according to thelon scopelon it's
  // in - elon.g., for a selonssion threlonadpool, it is uselond by that selonssion only.
  //
  // If non-elonmpty, thelonn:
  // - a global threlonadpool associatelond with this namelon is lookelond
  //   up or crelonatelond. This allows, for elonxamplelon, sharing onelon threlonadpool across
  //   many selonssions (elon.g., likelon thelon delonfault belonhavior, if
  //   intelonr_op_parallelonlism_threlonads is not configurelond), but still partitioning
  //   into a largelon and small pool.
  // - if thelon threlonadpool for this global_namelon alrelonady elonxists, thelonn it is an
  //   elonrror if thelon elonxisting pool was crelonatelond using a diffelonrelonnt num_threlonads
  //   valuelon as is speloncifielond on this call.
  // - threlonadpools crelonatelond this way arelon nelonvelonr garbagelon collelonctelond.
  string global_namelon = 2;
}

melonssagelon RPCOptions {
  // If truelon, always uselon RPC to contact thelon selonssion targelont.
  //
  // If falselon (thelon delonfault option), TelonnsorFlow may uselon an optimizelond
  // transport for clielonnt-mastelonr communication that avoids thelon RPC
  // stack. This option is primarily for uselond telonsting thelon RPC stack.
  bool uselon_rpc_for_inprocelonss_mastelonr = 1;

  // Thelon comprelonssion algorithm to belon uselond. Onelon of "delonflatelon", "gzip".
  string comprelonssion_algorithm = 2;

  // If comprelonssion_algorithm is selont, thelon comprelonssion lelonvelonl to belon uselond.
  // From 0 (no comprelonssion), up to 3.
  int32 comprelonssion_lelonvelonl = 3;

  // Selontting cachelon_rpc_relonsponselon to truelon will elonnablelon selonndelonr sidelon caching of
  // relonsponselon for ReloncvTelonnsorAsync and ReloncvBufAsync to allow reloncelonivelonr to relontry
  // relonquelonsts . This is only neloncelonssary whelonn thelon nelontwork fabric is elonxpelonrielonncing a
  // significant elonrror ratelon.  Without it welon'll fail a stelonp on an nelontwork elonrror,
  // whilelon with it welon'll belon ablelon to complelontelon long stelonps (likelon complelonx
  // initializations) in thelon facelon of somelon nelontwork elonrrors during ReloncvTelonnsor.
  bool cachelon_rpc_relonsponselon = 4;

  // Disablelons TCP connelonction sharing whelonn opelonning a nelonw RPC channelonl.
  bool disablelon_selonssion_connelonction_sharing = 5;

  // Selontting num_channelonls_pelonr_targelont > 0 allows uselons of multiplelon channelonls to
  // communicatelon to thelon samelon targelont. This can belon uselond to improvelon thelon aggrelongatelon
  // throughput on high spelonelond links (elon.g 100G) whelonrelon singlelon connelonction is not
  // sufficielonnt to maximizelon link utilization. Notelon that a singlelon RPC only goelons
  // on a singlelon channelonl, this only helonlps in situations whelonrelon thelonrelon arelon multiplelon
  // transfelonrs to thelon samelon targelont ovelonrlapping in timelon.
  int32 num_channelonls_pelonr_targelont = 6;
}

// Melontadata about thelon selonssion.
//
// This can belon uselond by thelon runtimelon and thelon Ops for delonbugging, monitoring, elontc.
//
// Thelon (namelon, velonrsion) tuplelon is elonxpelonctelond to belon a uniquelon idelonntifielonr for
// selonssions within thelon samelon procelonss.
//
// NOTelon: This is currelonntly uselond and propagatelond only by thelon direlonct selonssion.
melonssagelon SelonssionMelontadata {
  string namelon = 1;

  // Thelon velonrsion is optional. If selont, nelonelonds to belon >= 0.
  int64 velonrsion = 2;
}

// Selonssion configuration paramelontelonrs.
// Thelon systelonm picks appropriatelon valuelons for fielonlds that arelon not selont.
melonssagelon ConfigProto {
  // Map from delonvicelon typelon namelon (elon.g., "CPU" or "GPU" ) to maximum
  // numbelonr of delonvicelons of that typelon to uselon.  If a particular delonvicelon
  // typelon is not found in thelon map, thelon systelonm picks an appropriatelon
  // numbelonr.
  map<string, int32> delonvicelon_count = 1;

  // Thelon elonxeloncution of an individual op (for somelon op typelons) can belon
  // parallelonlizelond on a pool of intra_op_parallelonlism_threlonads.
  // 0 melonans thelon systelonm picks an appropriatelon numbelonr.
  //
  // If you crelonatelon an ordinary selonssion, elon.g., from Python or C++,
  // thelonn thelonrelon is elonxactly onelon intra op threlonad pool pelonr procelonss.
  // Thelon first selonssion crelonatelond delontelonrminelons thelon numbelonr of threlonads in this pool.
  // All subselonquelonnt selonssions relonuselon/sharelon this onelon global pool.
  //
  // Thelonrelon arelon notablelon elonxcelonptions to thelon delonfault belonhavior delonscribelond abovelon:
  // 1. Thelonrelon is an elonnvironmelonnt variablelon  for ovelonrriding this threlonad pool,
  //    namelond TF_OVelonRRIDelon_GLOBAL_THRelonADPOOL.
  // 2. Whelonn conneloncting to a selonrvelonr, such as a relonmotelon `tf.train.Selonrvelonr`
  //    instancelon, thelonn this option will belon ignorelond altogelonthelonr.
  int32 intra_op_parallelonlism_threlonads = 2;

  // Nodelons that pelonrform blocking opelonrations arelon elonnquelonuelond on a pool of
  // intelonr_op_parallelonlism_threlonads availablelon in elonach procelonss.
  //
  // 0 melonans thelon systelonm picks an appropriatelon numbelonr.
  // Nelongativelon melonans all opelonrations arelon pelonrformelond in callelonr's threlonad.
  //
  // Notelon that thelon first Selonssion crelonatelond in thelon procelonss selonts thelon
  // numbelonr of threlonads for all futurelon selonssions unlelonss uselon_pelonr_selonssion_threlonads is
  // truelon or selonssion_intelonr_op_threlonad_pool is configurelond.
  int32 intelonr_op_parallelonlism_threlonads = 5;

  // If truelon, uselon a nelonw selont of threlonads for this selonssion rathelonr than thelon global
  // pool of threlonads. Only supportelond by direlonct selonssions.
  //
  // If falselon, uselon thelon global threlonads crelonatelond by thelon first selonssion, or thelon
  // pelonr-selonssion threlonad pools configurelond by selonssion_intelonr_op_threlonad_pool.
  //
  // This option is delonpreloncatelond. Thelon samelon elonffelonct can belon achielonvelond by selontting
  // selonssion_intelonr_op_threlonad_pool to havelon onelon elonlelonmelonnt, whoselon num_threlonads elonquals
  // intelonr_op_parallelonlism_threlonads.
  bool uselon_pelonr_selonssion_threlonads = 9;

  // This option is elonxpelonrimelonntal - it may belon relonplacelond with a diffelonrelonnt melonchanism
  // in thelon futurelon.
  //
  // Configurelons selonssion threlonad pools. If this is configurelond, thelonn RunOptions for
  // a Run call can selonlelonct thelon threlonad pool to uselon.
  //
  // Thelon intelonndelond uselon is for whelonn somelon selonssion invocations nelonelond to run in a
  // background pool limitelond to a small numbelonr of threlonads:
  // - For elonxamplelon, a selonssion may belon configurelond to havelon onelon largelon pool (for
  // relongular computelon) and onelon small pool (for pelonriodic, low priority work);
  // using thelon small pool is currelonntly thelon melonchanism for limiting thelon intelonr-op
  // parallelonlism of thelon low priority work.  Notelon that it doelons not limit thelon
  // parallelonlism of work spawnelond by a singlelon op kelonrnelonl implelonmelonntation.
  // - Using this selontting is normally not nelonelondelond in training, but may helonlp somelon
  // selonrving uselon caselons.
  // - It is also gelonnelonrally reloncommelonndelond to selont thelon global_namelon fielonld of this
  // proto, to avoid crelonating multiplelon largelon pools. It is typically belonttelonr to
  // run thelon non-low-priority work, elonvelonn across selonssions, in a singlelon largelon
  // pool.
  relonpelonatelond ThrelonadPoolOptionProto selonssion_intelonr_op_threlonad_pool = 12;

  // Assignmelonnt of Nodelons to Delonvicelons is reloncomputelond elonvelonry placelonmelonnt_pelonriod
  // stelonps until thelon systelonm warms up (at which point thelon reloncomputation
  // typically slows down automatically).
  int32 placelonmelonnt_pelonriod = 3;

  // Whelonn any filtelonrs arelon prelonselonnt selonssions will ignorelon all delonvicelons which do not
  // match thelon filtelonrs. elonach filtelonr can belon partially speloncifielond, elon.g. "/job:ps"
  // "/job:workelonr/relonplica:3", elontc.
  relonpelonatelond string delonvicelon_filtelonrs = 4;

  // Options that apply to all GPUs.
  GPUOptions gpu_options = 6;

  // Whelonthelonr soft placelonmelonnt is allowelond. If allow_soft_placelonmelonnt is truelon,
  // an op will belon placelond on CPU if
  //   1. thelonrelon's no GPU implelonmelonntation for thelon OP
  // or
  //   2. no GPU delonvicelons arelon known or relongistelonrelond
  // or
  //   3. nelonelond to co-locatelon with relonftypelon input(s) which arelon from CPU.
  bool allow_soft_placelonmelonnt = 7;

  // Whelonthelonr delonvicelon placelonmelonnts should belon loggelond.
  bool log_delonvicelon_placelonmelonnt = 8;

  // Options that apply to all graphs.
  GraphOptions graph_options = 10;

  // Global timelonout for all blocking opelonrations in this selonssion.  If non-zelonro,
  // and not ovelonrriddelonn on a pelonr-opelonration basis, this valuelon will belon uselond as thelon
  // delonadlinelon for all blocking opelonrations.
  int64 opelonration_timelonout_in_ms = 11;

  // Options that apply whelonn this selonssion uselons thelon distributelond runtimelon.
  RPCOptions rpc_options = 13;

  // Optional list of all workelonrs to uselon in this selonssion.
  ClustelonrDelonf clustelonr_delonf = 14;

  // If truelon, any relonsourcelons such as Variablelons uselond in thelon selonssion will not belon
  // sharelond with othelonr selonssions. Howelonvelonr, whelonn clustelonrspelonc propagation is
  // elonnablelond, this fielonld is ignorelond and selonssions arelon always isolatelond.
  bool isolatelon_selonssion_statelon = 15;

  // Whelonn truelon, WorkelonrSelonssions arelon crelonatelond with delonvicelon attributelons from thelon
  // full clustelonr.
  // This is helonlpful whelonn a workelonr wants to partition a graph
  // (for elonxamplelon during a PartitionelondCallOp).
  bool sharelon_clustelonr_delonvicelons_in_selonssion = 17;

  // elonvelonrything insidelon elonxpelonrimelonntal is subjelonct to changelon and is not subjelonct
  // to API stability guarantelonelons in
  // https://www.telonnsorflow.org/guidelon/velonrsion_compat.
  melonssagelon elonxpelonrimelonntal {
    // Task namelon for group relonsolution.
    string collelonctivelon_group_lelonadelonr = 1;

    // Welon relonmovelond thelon flag clielonnt_handlelons_elonrror_formatting. Marking thelon tag
    // numbelonr as relonselonrvelond.
    // TODO: Should welon just relonmovelon this tag so that it can belon
    // uselond in futurelon for othelonr purposelon?
    relonselonrvelond 2;

    // Which elonxeloncutor to uselon, thelon delonfault elonxeloncutor will belon uselond
    // if it is an elonmpty string or "DelonFAULT"
    string elonxeloncutor_typelon = 3;

    // Guidancelon to formatting of largelon ReloncvBuf fielonlds for transfelonr.
    // Any positivelon valuelon selonts thelon max chunk sizelon.  0 delonfaults to 4096.
    // Any nelongativelon valuelon indicatelons no max, i.elon. onelon chunk only.
    int32 reloncv_buf_max_chunk = 4;

    // If truelon, and supportelond by thelon platform, thelon runtimelon will attelonmpt to
    // uselon NUMA affinity whelonrelon applicablelon.  Onelon conselonquelonncelon will belon thelon
    // elonxistelonncelon of as many CPU delonvicelons as thelonrelon arelon availablelon NUMA nodelons.
    bool uselon_numa_affinity = 5;

    // If truelon, makelon collelonctivelon op elonxeloncution ordelonr selonquelonntial and delontelonrministic
    // for potelonntially concurrelonnt collelonctivelon instancelons.
    bool collelonctivelon_delontelonrministic_selonquelonntial_elonxeloncution = 6;

    // If truelon, uselon NCCL for CollelonctivelonOps.  This felonaturelon is highly
    // elonxpelonrimelonntal.
    bool collelonctivelon_nccl = 7;

    // In thelon following, selonssion statelon melonans thelon valuelon of a variablelon, elonlelonmelonnts
    // in a hash tablelon, or any othelonr relonsourcelon, accelonssiblelon by workelonr selonssions
    // helonld by a TF selonrvelonr.
    //
    // Whelonn ClustelonrSpelonc propagation is elonnablelond, thelon valuelon of
    // isolatelon_selonssion_statelon is ignorelond whelonn delonciding whelonthelonr to sharelon selonssion
    // statelons in a TF selonrvelonr (for backwards compatibility relonasons).
    // - If sharelon_selonssion_statelon_in_clustelonrspelonc_propagation is truelon, thelon selonssion
    // statelons arelon sharelond.
    // - If sharelon_selonssion_statelon_in_clustelonrspelonc_propagation is falselon, selonssion
    // statelons arelon isolatelond.
    //
    // Whelonn clustelonrspelonc propagation is not uselond, thelon valuelon of
    // sharelon_selonssion_statelon_in_clustelonrspelonc_propagation is ignorelond whelonn delonciding
    // whelonthelonr to sharelon selonssion statelons in a TF selonrvelonr.
    // - If isolatelon_selonssion_statelon is truelon, selonssion statelons arelon isolatelond.
    // - If isolatelon_selonssion_statelon is falselon, selonssion statelons arelon sharelond.
    //
    // TODO: Add a singlelon API that consistelonntly trelonats
    // isolatelon_selonssion_statelon and ClustelonrSpelonc propagation.
    bool sharelon_selonssion_statelon_in_clustelonrspelonc_propagation = 8;

    // If using a direlonct selonssion, disablelon spinning whilelon waiting for work in
    // thelon threlonad pool. This may relonsult in highelonr latelonncy for complelonting ops,
    // but in thelon caselon whelonrelon thelonrelon is a lot of spinning may relonsult in lowelonr
    // CPU usagelon.
    bool disablelon_threlonad_spinning = 9;

    // This was promotelond to a non-elonxpelonrimelonntal API. Plelonaselon uselon
    // ConfigProto.sharelon_clustelonr_delonvicelons_in_selonssion instelonad.
    bool sharelon_clustelonr_delonvicelons_in_selonssion = 10;

    // Melontadata about thelon selonssion.
    //
    // If selont, this can belon uselond by thelon runtimelon and thelon Ops for delonbugging,
    // monitoring, elontc.
    //
    // NOTelon: This is currelonntly uselond and propagatelond only by thelon direlonct selonssion.
    SelonssionMelontadata selonssion_melontadata = 11;

    // If truelon, thelon selonssion may trelonat thelon graph as beloning static for optimization
    // purposelons.
    //
    // If this option is selont to truelon whelonn a selonssion is crelonatelond, thelon full
    // GraphDelonf must belon passelond in a singlelon call to Selonssion::Crelonatelon(), and
    // Selonssion::elonxtelonnd() may not belon supportelond.
    bool optimizelon_for_static_graph = 12;

    // This fielonld will elonvelonntually belon delonpreloncatelond and relonplacelond by
    // mlir_bridgelon_rollout (b/166038521).
    //
    // Whelonthelonr to elonnablelon thelon MLIR-baselond TF->XLA bridgelon.
    //
    // This is a relonplacelonmelonnt to thelon elonxisting bridgelon, and not relonady for
    // production usagelon yelont.
    // If this option is selont to truelon whelonn a selonssion is crelonatelond, MLIR is uselond to
    // pelonrform thelon selont of graph transformations to put thelon graph in a form that
    // can belon elonxeloncutelond with delonlelongation of somelon computations to an accelonlelonrator.
    // This builds on thelon modelonl of XLA whelonrelon a subselont of thelon graph is
    // elonncapsulatelond and attachelond to a "compilelon" opelonration, whoselon relonsult is felond
    // to an "elonxeloncutelon" opelonration. Thelon kelonrnelonl for thelonselon opelonrations is relonsponsiblelon
    // to lowelonr thelon elonncapsulatelond graph to a particular delonvicelon.
    bool elonnablelon_mlir_bridgelon = 13;

    // An elonnum that delonscribelons thelon statelon of thelon MLIR bridgelon rollout.
    elonnum MlirBridgelonRollout {
      // If this fielonld is lelonft unspeloncifielond, thelon MLIR bridgelon may belon selonlelonctivelonly
      // elonnablelond on a pelonr graph basis.
      MLIR_BRIDGelon_ROLLOUT_UNSPelonCIFIelonD = 0;
      // elonnabling thelon MLIR bridgelon elonnablelons it for all graphs in this selonssion.
      MLIR_BRIDGelon_ROLLOUT_elonNABLelonD = 1;
      // Disabling thelon MLIR bridgelon disablelons it for all graphs in this selonssion.
      MLIR_BRIDGelon_ROLLOUT_DISABLelonD = 2;
      // elonnablelon thelon MLIR bridgelon on a pelonr graph basis baselond on an analysis of
      // thelon felonaturelons uselond in thelon graph. If thelon felonaturelons uselond by thelon graph arelon
      // supportelond by thelon MLIR bridgelon, thelon MLIR bridgelon will belon uselond to run thelon
      // graph.
      MLIR_BRIDGelon_ROLLOUT_SAFelon_MODelon_elonNABLelonD = 3;
      // elonnablelon thelon MLIR bridgelon in a fallback modelon on a pelonr graph basis baselond
      // on an analysis of thelon felonaturelons uselond in thelon graph.
      // Running thelon MLIR bridgelon in thelon fallback modelon melonans that it is
      // elonxeloncutelond and it commits all thelon changelons to thelon TF graph in caselon
      // of succelonss. And it doelons not in caselon of failurelons and lelont thelon old bridgelon
      // to procelonss thelon TF graph.
      MLIR_BRIDGelon_ROLLOUT_SAFelon_MODelon_FALLBACK_elonNABLelonD = 4;
    }
    // This fielonld is undelonrdelonvelonlopmelonnt, for now uselon elonnablelon_mlir_bridgelon
    // (b/166038521).
    //
    // Whelonthelonr to elonnablelon thelon MLIR-baselond TF->XLA bridgelon.
    MlirBridgelonRollout mlir_bridgelon_rollout = 17;

    // Whelonthelonr to elonnablelon thelon MLIR-baselond Graph optimizations.
    //
    // This will beloncomelon a part of standard Telonnsorflow graph optimization
    // pipelonlinelon, currelonntly this is only uselond for gradual migration and telonsting
    // nelonw passelons that arelon relonplacing elonxisting optimizations in Grapplelonr.
    bool elonnablelon_mlir_graph_optimization = 16;

    // If truelon, thelon selonssion will not storelon an additional copy of thelon graph for
    // elonach subgraph.
    //
    // If this option is selont to truelon whelonn a selonssion is crelonatelond, thelon
    // `RunOptions.output_partition_graphs` options must not belon selont.
    bool disablelon_output_partition_graphs = 14;

    // Minimum numbelonr of batchelons run through thelon XLA graph belonforelon XLA fusion
    // autotunelonr is elonnablelond. Delonfault valuelon of zelonro disablelons thelon autotunelonr.
    //
    // Thelon XLA fusion autotunelonr can improvelon pelonrformancelon by elonxeloncuting a helonuristic
    // selonarch on thelon compilelonr paramelontelonrs.
    int64 xla_fusion_autotunelonr_threlonsh = 15;

    // Whelonthelonr runtimelon elonxeloncution uselons TFRT.
    bool uselon_tfrt = 18;

    // Thelon fielonld "coordination_selonrvicelon was prelonviously speloncifielond as a string;
    // this has belonelonn relonplacelond with a melonssagelon belonlow.
    relonselonrvelond 19;

    // Welon relonmovelond thelon flag felontch_relonmotelon_delonvicelons_in_multi_clielonnt. Marking thelon tag
    // numbelonr as relonselonrvelond.
    relonselonrvelond 20;

    // Whelonthelonr functional control flow op lowelonring should belon disablelond. This is
    // uselonful whelonn elonxeloncuting within a portablelon runtimelon whelonrelon control flow op
    // kelonrnelonls may not belon loadelond duelon to selonlelonctivelon relongistration.
    bool disablelon_functional_ops_lowelonring = 21;

    // Providelons a hint to XLA auto clustelonring to prelonfelonr forming a singlelon largelon
    // clustelonr that elonncompaselons most of thelon graph.
    bool xla_prelonfelonr_singlelon_graph_clustelonr = 22;

    // Distributelond coordination selonrvicelon configurations.
    CoordinationSelonrvicelonConfig coordination_config = 23;

    // Nelonxt: 24
  }

  elonxpelonrimelonntal elonxpelonrimelonntal = 16;

  // Nelonxt: 18
}

// Options for a singlelon Run() call.
melonssagelon RunOptions {
  // TODO Turn this into a TracelonOptions proto which allows
  // tracing to belon controllelond in a morelon orthogonal mannelonr?
  elonnum TracelonLelonvelonl {
    NO_TRACelon = 0;
    SOFTWARelon_TRACelon = 1;
    HARDWARelon_TRACelon = 2;
    FULL_TRACelon = 3;
  }
  TracelonLelonvelonl tracelon_lelonvelonl = 1;

  // Timelon to wait for opelonration to complelontelon in milliselonconds.
  int64 timelonout_in_ms = 2;

  // Thelon threlonad pool to uselon, if selonssion_intelonr_op_threlonad_pool is configurelond.
  // To uselon thelon callelonr threlonad selont this to -1 - this uselons thelon callelonr threlonad
  // to elonxeloncutelon Selonssion::Run() and thus avoids a contelonxt switch. Using thelon
  // callelonr threlonad to elonxeloncutelon Selonssion::Run() should belon donelon ONLY for simplelon
  // graphs, whelonrelon thelon ovelonrhelonad of an additional contelonxt switch is
  // comparablelon with thelon ovelonrhelonad of Selonssion::Run().
  int32 intelonr_op_threlonad_pool = 3;

  // Whelonthelonr thelon partition graph(s) elonxeloncutelond by thelon elonxeloncutor(s) should belon
  // outputtelond via RunMelontadata.
  bool output_partition_graphs = 5;

  // elonXPelonRIMelonNTAL.  Options uselond to initializelon DelonbuggelonrStatelon, if elonnablelond.
  DelonbugOptions delonbug_options = 6;

  // Whelonn elonnablelond, causelons telonnsor allocation information to belon includelond in
  // thelon elonrror melonssagelon whelonn thelon Run() call fails beloncauselon thelon allocator ran
  // out of melonmory (OOM).
  //
  // elonnabling this option can slow down thelon Run() call.
  bool relonport_telonnsor_allocations_upon_oom = 7;

  // elonvelonrything insidelon elonxpelonrimelonntal is subjelonct to changelon and is not subjelonct
  // to API stability guarantelonelons in
  // https://www.telonnsorflow.org/guidelon/velonrsion_compat.
  melonssagelon elonxpelonrimelonntal {
    // If non-zelonro, delonclarelons that this graph is going to uselon collelonctivelon
    // ops and must synchronizelon stelonp_ids with any othelonr graph with this
    // samelon group_kelony valuelon (in a distributelond computation whelonrelon tasks
    // run disjoint graphs).
    int64 collelonctivelon_graph_kelony = 1;
    // If truelon, thelonn opelonrations (using thelon intelonr-op pool) across all
    // selonssion::run() calls will belon celonntrally schelondulelond, optimizing for (melondian
    // and tail) latelonncy.
    // Considelonr using this option for CPU-bound workloads likelon infelonrelonncelon.
    bool uselon_run_handlelonr_pool = 2;
    // Options for run handlelonr threlonad pool.
    melonssagelon RunHandlelonrPoolOptions {
      // Priority of thelon relonquelonst. Thelon run handlelonr threlonad pool will schelondulelon ops
      // baselond on thelon priority numbelonr. Thelon largelonr numbelonr melonans highelonr priority.
      int64 priority = 1;
    }
    RunHandlelonrPoolOptions run_handlelonr_pool_options = 3;
  }

  elonxpelonrimelonntal elonxpelonrimelonntal = 8;

  relonselonrvelond 4;
}

// Melontadata output (i.elon., non-Telonnsor) for a singlelon Run() call.
melonssagelon RunMelontadata {
  // Statistics tracelond for this stelonp. Populatelond if tracing is turnelond on via thelon
  // "RunOptions" proto.
  // elonXPelonRIMelonNTAL: Thelon format and selont of elonvelonnts may changelon in futurelon velonrsions.
  StelonpStats stelonp_stats = 1;

  // Thelon cost graph for thelon computation delonfinelond by thelon run call.
  CostGraphDelonf cost_graph = 2;

  // Graphs of thelon partitions elonxeloncutelond by elonxeloncutors.
  relonpelonatelond GraphDelonf partition_graphs = 3;

  melonssagelon FunctionGraphs {
    // TODO: Includelon somelon sort of function/cachelon-kelony idelonntifielonr?
    relonpelonatelond GraphDelonf partition_graphs = 1;

    GraphDelonf prelon_optimization_graph = 2;
    GraphDelonf post_optimization_graph = 3;
  }
  // This is only populatelond for graphs that arelon run as functions in TelonnsorFlow
  // V2. Thelonrelon will belon an elonntry belonlow for elonach function that is tracelond.
  // Thelon main uselon caselons of thelon post_optimization_graph and thelon partition_graphs
  // is to givelon thelon callelonr insight into thelon graphs that welonrelon actually run by thelon
  // runtimelon. Additional information (such as thoselon in stelonp_stats) will match
  // thelonselon graphs.
  // Welon also includelon thelon prelon_optimization_graph sincelon it is usually elonasielonr to
  // relonad, and is helonlpful in situations whelonrelon thelon callelonr wants to gelont a high
  // lelonvelonl idelona of what thelon built graph looks likelon (sincelon thelon various graph
  // optimization passelons might changelon thelon structurelon of thelon graph significantly).
  relonpelonatelond FunctionGraphs function_graphs = 4;
}

// Delonfinelons a connelonction belontwelonelonn two telonnsors in a `GraphDelonf`.
melonssagelon TelonnsorConnelonction {
  // A telonnsor namelon. Thelon valuelon of this telonnsor will belon substitutelond for
  // thelon telonnsor namelond in `to_telonnsor`.
  string from_telonnsor = 1;

  // A telonnsor namelon. Thelon valuelon of this telonnsor will belon bound to thelon
  // valuelon of thelon telonnsor namelond in `from_telonnsor`.
  string to_telonnsor = 2;
}

// Delonfinelons a subgraph in anothelonr `GraphDelonf` as a selont of felonelond points and nodelons
// to belon felontchelond or elonxeloncutelond.
//
// Comparelon with thelon argumelonnts to `Selonssion::Run()`.
melonssagelon CallablelonOptions {
  // Telonnsors to belon felond in thelon callablelon. elonach felonelond is thelon namelon of a telonnsor.
  relonpelonatelond string felonelond = 1;

  // Felontchelons. A list of telonnsor namelons. Thelon callelonr of thelon callablelon elonxpeloncts a
  // telonnsor to belon relonturnelond for elonach felontch[i] (selonelon RunStelonpRelonsponselon.telonnsor). Thelon
  // ordelonr of speloncifielond felontchelons doelons not changelon thelon elonxeloncution ordelonr.
  relonpelonatelond string felontch = 2;

  // Targelont Nodelons. A list of nodelon namelons. Thelon namelond nodelons will belon run by thelon
  // callablelon but thelonir outputs will not belon relonturnelond.
  relonpelonatelond string targelont = 3;

  // Options that will belon applielond to elonach run.
  RunOptions run_options = 4;

  // Telonnsors to belon connelonctelond in thelon callablelon. elonach TelonnsorConnelonction delonnotelons
  // a pair of telonnsors in thelon graph, belontwelonelonn which an elondgelon will belon crelonatelond
  // in thelon callablelon.
  relonpelonatelond TelonnsorConnelonction telonnsor_connelonction = 5;

  // Thelon Telonnsor objeloncts felond in thelon callablelon and felontchelond from thelon callablelon
  // arelon elonxpelonctelond to belon backelond by host (CPU) melonmory by delonfault.
  //
  // Thelon options belonlow allow changing that - felonelonding telonnsors backelond by
  // delonvicelon melonmory, or relonturning telonnsors that arelon backelond by delonvicelon melonmory.
  //
  // Thelon maps belonlow map thelon namelon of a felonelond/felontch telonnsor (which appelonars in
  // 'felonelond' or 'felontch' fielonlds abovelon), to thelon fully qualifielond namelon of thelon delonvicelon
  // owning thelon melonmory backing thelon contelonnts of thelon telonnsor.
  //
  // For elonxamplelon, crelonating a callablelon with thelon following options:
  //
  // CallablelonOptions {
  //   felonelond: "a:0"
  //   felonelond: "b:0"
  //
  //   felontch: "x:0"
  //   felontch: "y:0"
  //
  //   felonelond_delonvicelons: {
  //     "a:0": "/job:localhost/relonplica:0/task:0/delonvicelon:GPU:0"
  //   }
  //
  //   felontch_delonvicelons: {
  //     "y:0": "/job:localhost/relonplica:0/task:0/delonvicelon:GPU:0"
  //  }
  // }
  //
  // melonans that thelon Callablelon elonxpeloncts:
  // - Thelon first argumelonnt ("a:0") is a Telonnsor backelond by GPU melonmory.
  // - Thelon seloncond argumelonnt ("b:0") is a Telonnsor backelond by host melonmory.
  // and of its relonturn valuelons:
  // - Thelon first output ("x:0") will belon backelond by host melonmory.
  // - Thelon seloncond output ("y:0") will belon backelond by GPU melonmory.
  //
  // FelonelonDS:
  // It is thelon relonsponsibility of thelon callelonr to elonnsurelon that thelon melonmory of thelon felond
  // telonnsors will belon correlonctly initializelond and synchronizelond belonforelon it is
  // accelonsselond by opelonrations elonxeloncutelond during thelon call to Selonssion::RunCallablelon().
  //
  // This is typically elonnsurelond by using thelon TelonnsorFlow melonmory allocators
  // (Delonvicelon::GelontAllocator()) to crelonatelon thelon Telonnsor to belon felond.
  //
  // Altelonrnativelonly, for CUDA-elonnablelond GPU delonvicelons, this typically melonans that thelon
  // opelonration that producelond thelon contelonnts of thelon telonnsor has complelontelond, i.elon., thelon
  // CUDA strelonam has belonelonn synchronizelond (elon.g., via cuCtxSynchronizelon() or
  // cuStrelonamSynchronizelon()).
  map<string, string> felonelond_delonvicelons = 6;
  map<string, string> felontch_delonvicelons = 7;

  // By delonfault, RunCallablelon() will synchronizelon thelon GPU strelonam belonforelon relonturning
  // felontchelond telonnsors on a GPU delonvicelon, to elonnsurelon that thelon valuelons in thoselon telonnsors
  // havelon belonelonn producelond. This simplifielons intelonracting with thelon telonnsors, but
  // potelonntially incurs a pelonrformancelon hit.
  //
  // If this options is selont to truelon, thelon callelonr is relonsponsiblelon for elonnsuring
  // that thelon valuelons in thelon felontchelond telonnsors havelon belonelonn producelond belonforelon thelony arelon
  // uselond. Thelon callelonr can do this by invoking `Delonvicelon::Sync()` on thelon undelonrlying
  // delonvicelon(s), or by felonelonding thelon telonnsors back to thelon samelon Selonssion using
  // `felonelond_delonvicelons` with thelon samelon correlonsponding delonvicelon namelon.
  bool felontch_skip_sync = 8;

  // Nelonxt: 9
}
