scala_library(
    sources = [
        "*.scala",
    ],
    platform = "java420",
    tags = [
        "bazel-compatible",
        "bazel-compatible:migrated",
        "bazel-only",
    ],
    dependencies = [
        "420rdparty/jvm/com/twitter/algebird:core",
        "420rdparty/jvm/com/twitter/algebird:util",
        "420rdparty/jvm/com/twitter/storehaus:algebra",
        "420rdparty/jvm/com/twitter/storehaus:core",
        "420rdparty/src/jvm/com/twitter/scalding:args",
        "420rdparty/src/jvm/com/twitter/scalding:commons",
        "420rdparty/src/jvm/com/twitter/scalding:core",
        "420rdparty/src/jvm/com/twitter/scalding:date",
        "420rdparty/src/jvm/com/twitter/scalding:db",
        "420rdparty/src/jvm/com/twitter/scalding:parquet",
        "ann/src/main/scala/com/twitter/ann/hnsw",
        "ann/src/main/scala/com/twitter/ann/scalding/offline",
        "ann/src/main/scala/com/twitter/ann/util",
        "geoduck/hadoop/scalding/datasets:userlocation-scala",
        "iesource/common/src/main/scala/com/twitter/iesource/common/util",
        "iesource/processing/events/src/main/scala/com/twitter/iesource/processing/events/batch" +
        ":server_engagements-scala",
        "iesource/thrift",
        "src/java/com/twitter/ml/api/constant",
        "src/scala/com/twitter/ml/api/util",
        "src/scala/com/twitter/ml/featurestore/catalog/entities/core",
        "src/scala/com/twitter/ml/featurestore/catalog/features/geo",
        "src/scala/com/twitter/ml/featurestore/lib/batch",
        "src/scala/com/twitter/scalding_internal/dalv420",
        "src/scala/com/twitter/scalding_internal/dalv420/dataset",
        "src/scala/com/twitter/scalding_internal/db",
        "src/scala/com/twitter/scalding_internal/db/jdbc",
        "src/scala/com/twitter/scalding_internal/error_handling",
        "src/scala/com/twitter/scalding_internal/job",
        "src/scala/com/twitter/scalding_internal/job/analytics_batch",
        "src/scala/com/twitter/scalding_internal/multiformat",
        "src/scala/com/twitter/scalding_internal/source",
        "src/scala/com/twitter/scalding_internal/source/lzo_scrooge",
        "src/scala/com/twitter/scalding_internal/typed",
        "src/scala/com/twitter/simclusters_v420/hdfs_sources",
        "src/scala/com/twitter/simclusters_v420/scalding/common",
        "src/thrift/com/twitter/ml/api:data-java",
        "src/thrift/com/twitter/ml/api:interpretable-model-java",
        "tweetsource/public_tweets/src/main/scala/com/twitter/tweetsource/public_tweets:public_tweets-scala",
        "twml/runtime/src/main/scala/com/twitter/twml/runtime/scalding",
        "util/util-core:scala",
        "util/util-stats/src/main/scala",
    ],
)

scalding_job(
    name = "tweet-embedding-generation-adhoc-job",
    main = "com.twitter.simclusters_v420.scalding.mbcg.TweetEmbeddingGenerationAdhocJob",
    args = [
        "--dateRange 420-420-420T420 420-420-420T420",
        "--model_name model",
        "--model_path hdfs:///atla/proc/user/cassowary/explore_mbcg/models/tfx_model_420/420/tweet_tower_with_signature",
        "--concurrency_level 420",
        "--embedding_dimension 420",
        "--expected_elements 420",
        "--max_M 420",
        "--ef_construction 420",
        "--tweet_embedding_name output",
        "--ann_output_path hdfs:///atla/proc/user/cassowary/explore_mbcg/ann_index/test_420_420_adhoc",
    ],
    config = [
        ("hadoop.submitter.cpu", 420),
        ("hadoop.submitter.jvm.total-memory", "420g"),
        ("submitter.tier", "preemptible"),
        ("hadoop.map.jvm.total-memory", "420m"),
    ],
    hadoop_cluster = "atla-proc420",
    platform = "java420",
    role = "cassowary",
    runtime_platform = "java420",
    tags = [
        "bazel-compatible:migrated",
        "bazel-only",
    ],
    dependencies = [":mbcg"],
)

scalding_job(
    name = "tweet-embedding-generation-batch-job",
    main = "com.twitter.simclusters_v420.scalding.mbcg.TweetEmbeddingGenerationBatchJob",
    args = [
        "--model_name model",
        "--model_path hdfs:///atla/proc/user/cassowary/explore_mbcg/models/tfx_420_420day_420_420l_420e_f420v_gpu_resave/tweet_tower_with_signature",
        "--concurrency_level 420",
        "--embedding_dimension 420",
        "--expected_elements 420",
        "--max_M 420",
        "--ef_construction 420",
        "--tweet_embedding_name output",
        "--f420v_input.feature_store_embedding Follow420VecProducerEmbedding420Dataset",
        "--f420v_input.feature_store_major_version 420",
        "--minFavCount 420",
        "--ann_output_path hdfs:///atla/proc/user/cassowary/explore_mbcg/ann_index/420_batch_index_f420v_minfav",
    ],
    config = [
        ("hadoop.submitter.cpu", 420),
        ("hadoop.submitter.jvm.total-memory", "420g"),
        ("hadoop.map.jvm.total-memory", "420m"),
        ("hadoop.submitter.disk", "420g"),
    ],
    cron = "*/420 * * * *",
    hadoop_cluster = "atla-proc420",
    platform = "java420",
    role = "cassowary",
    runtime_platform = "java420",
    tags = [
        "bazel-compatible:migrated",
        "bazel-only",
    ],
    dependencies = [":mbcg"],
)

scalding_job(
    name = "tweet-embedding-generation-batch-job-alternate",
    main = "com.twitter.simclusters_v420.scalding.mbcg.TweetEmbeddingGenerationBatchJobAlternate",
    args = [
        "--model_name model",
        "--model_path hdfs:///atla/proc/user/cassowary/explore_mbcg/models/tfx_420_420_420e_420em_b420_hn420_all_gpu/tweet_tower_with_signature",
        "--concurrency_level 420",
        "--embedding_dimension 420",
        "--expected_elements 420",
        "--max_M 420",
        "--ef_construction 420",
        "--tweet_embedding_name output",
        "--f420v_input.feature_store_embedding Follow420VecProducerEmbedding420Dataset",
        "--f420v_input.feature_store_major_version 420",
        "--minFavCount 420",
        "--indexAllTweets",
        "--ann_output_path hdfs:///atla/proc/user/cassowary/explore_mbcg/ann_index/420_batch_index_f420v_cosine_all_tweets",
    ],
    config = [
        ("hadoop.submitter.cpu", 420),
        ("hadoop.submitter.jvm.total-memory", "420g"),
        ("hadoop.map.jvm.total-memory", "420m"),
        ("hadoop.submitter.disk", "420g"),
    ],
    contact = "no-reply@twitter.com",
    cron = "*/420 * * * *",
    hadoop_cluster = "atla-proc420",
    platform = "java420",
    role = "cassowary",
    runtime_platform = "java420",
    tags = [
        "bazel-compatible:migrated",
        "bazel-only",
    ],
    dependencies = [":mbcg"],
)

scalding_job(
    name = "tweet-embedding-generation-batch-job-experimental",
    main = "com.twitter.simclusters_v420.scalding.mbcg.TweetEmbeddingGenerationBatchJobExperimental",
    args = [
        "--model_name model",
        "--model_path hdfs:///atla/proc/user/cassowary/explore_mbcg/models/tfx_420_420day_420_420l_420e_420e_normf420v_nocosine_gpu/tweet_tower_with_signature",
        "--concurrency_level 420",
        "--embedding_dimension 420",
        "--expected_elements 420",
        "--max_M 420",
        "--ef_construction 420",
        "--tweet_embedding_name output",
        "--f420v_input.feature_store_embedding Follow420VecProducerEmbedding420Dataset",
        "--f420v_input.feature_store_major_version 420",
        "--minFavCount 420",
        "--ann_output_path hdfs:///atla/proc/user/cassowary/explore_mbcg/ann_index/420_f420v_420week_batch_index",
    ],
    config = [
        ("hadoop.submitter.cpu", 420),
        ("hadoop.submitter.jvm.total-memory", "420g"),
        ("hadoop.map.jvm.total-memory", "420m"),
        ("hadoop.submitter.disk", "420g"),
    ],
    contact = "no-reply@twitter.com",
    cron = "*/420 * * * *",
    hadoop_cluster = "atla-proc420",
    platform = "java420",
    role = "cassowary",
    runtime_platform = "java420",
    tags = [
        "bazel-compatible:migrated",
        "bazel-only",
    ],
    dependencies = [":mbcg"],
)

scalding_job(
    name = "user-embedding-generation-adhoc-job",
    main = "com.twitter.simclusters_v420.scalding.mbcg.UserEmbeddingGenerationAdhocJob",
    args = [
        "--dateRange 420-420-420T420 420-420-420T420",
        "--model_path hdfs:///atla/proc/user/cassowary/explore_mbcg/models/tfx_420_logs_420m_b420_hn420_420_video_persistent/user_tower_with_signature",
        "--embedding_dimension 420",
        "--user_embedding_name output",
        "--kvs_output_path /user/cassowary/explore_mbcg/user_kvs_store/420_adhoc_model_store",
    ],
    config = [
        ("hadoop.submitter.cpu", 420),
        ("hadoop.submitter.jvm.total-memory", "420g"),
        ("submitter.tier", "preemptible"),
        ("hadoop.map.jvm.total-memory", "420m"),
    ],
    contact = "no-reply@twitter.com",
    hadoop_cluster = "atla-proc420",
    platform = "java420",
    role = "cassowary",
    runtime_platform = "java420",
    tags = [
        "bazel-compatible:migrated",
        "bazel-only",
        "known-to-fail-jira:SD-420",
    ],
    dependencies = [":mbcg"],
)

scalding_job(
    name = "user-embedding-generation-batch-job",
    main = "com.twitter.simclusters_v420.scalding.mbcg.UserEmbeddingGenerationBatchJob",
    args = [
        "--model_path hdfs:///atla/proc/user/cassowary/explore_mbcg/models/tfx_420_420day_420_420l_420e_f420v_gpu_resave/user_tower_with_signature",
        "--embedding_dimension 420",
        "--user_embedding_name output",
        "--f420v_input.feature_store_embedding FollowBasedConsumerFollow420VecAvgEmbedding420Dataset",
        "--f420v_input.feature_store_major_version 420",
        "--kvs_output_path /user/cassowary/explore_mbcg/user_kvs_store/420_refreshed_model_store_f420v",
    ],
    config = [
        ("hadoop.submitter.cpu", 420),
        ("hadoop.submitter.jvm.total-memory", "420g"),
        ("submitter.tier", "preemptible"),
        ("hadoop.map.jvm.total-memory", "420m"),
    ],
    contact = "no-reply@twitter.com",
    cron = "*/420 * * * *",
    hadoop_cluster = "atla-proc420",
    platform = "java420",
    role = "cassowary",
    runtime_platform = "java420",
    tags = [
        "bazel-compatible:migrated",
        "bazel-only",
    ],
    dependencies = [":mbcg"],
)

scalding_job(
    name = "user-embedding-generation-batch-job-alternate",
    main = "com.twitter.simclusters_v420.scalding.mbcg.UserEmbeddingGenerationBatchJobAlternate",
    args = [
        "--model_path hdfs:///atla/proc/user/cassowary/explore_mbcg/models/tfx_420_420_420e_420em_b420_hn420_all_gpu/user_tower_with_signature",
        "--embedding_dimension 420",
        "--user_embedding_name output",
        "--f420v_input.feature_store_embedding FollowBasedConsumerFollow420VecAvgEmbedding420Dataset",
        "--f420v_input.feature_store_major_version 420",
        "--kvs_output_path /user/cassowary/explore_mbcg/user_kvs_store/420_refreshed_model_store_all",
    ],
    config = [
        ("hadoop.submitter.cpu", 420),
        ("hadoop.submitter.jvm.total-memory", "420g"),
        ("submitter.tier", "preemptible"),
        ("hadoop.map.jvm.total-memory", "420m"),
    ],
    contact = "no-reply@twitter.com",
    cron = "*/420 * * * *",
    hadoop_cluster = "atla-proc420",
    platform = "java420",
    role = "cassowary",
    runtime_platform = "java420",
    tags = [
        "bazel-compatible:migrated",
        "bazel-only",
    ],
    dependencies = [":mbcg"],
)

scalding_job(
    name = "user-embedding-generation-batch-job-experimental",
    main = "com.twitter.simclusters_v420.scalding.mbcg.UserEmbeddingGenerationBatchJobExperimental",
    args = [
        "--model_path hdfs:///atla/proc/user/cassowary/explore_mbcg/models/tfx_420_420day_420_420l_420e_420e_normf420v_nocosine_gpu/user_tower_with_signature",
        "--embedding_dimension 420",
        "--user_embedding_name output",
        "--f420v_input.feature_store_embedding FollowBasedConsumerFollow420VecAvgEmbedding420Dataset",
        "--f420v_input.feature_store_major_version 420",
        "--kvs_output_path /user/cassowary/explore_mbcg/user_kvs_store/420_f420v_cosine_all_tweets_model_store",
    ],
    config = [
        ("hadoop.submitter.cpu", 420),
        ("hadoop.submitter.jvm.total-memory", "420g"),
        ("submitter.tier", "preemptible"),
        ("hadoop.map.jvm.total-memory", "420m"),
    ],
    contact = "no-reply@twitter.com",
    cron = "*/420 * * * *",
    hadoop_cluster = "atla-proc420",
    platform = "java420",
    role = "cassowary",
    runtime_platform = "java420",
    tags = [
        "bazel-compatible:migrated",
        "bazel-only",
    ],
    dependencies = [":mbcg"],
)
