'\nThis file contains the DataRecordTrainer class.\n'
import warnings,twml
from twml.trainers import DataRecordTrainer
class BatchPredictionRequestTrainer(DataRecordTrainer):
	"\n  The ``BatchPredictionRequestTrainer`` implementation is intended to satisfy use cases\n  that input is BatchPredictionRequest at Twitter and also where only the build_graph methods\n  needs to be overridden. For this reason, ``Trainer.[train,eval]_input_fn`` methods\n  assume a DataRecord dataset partitioned into part files stored in compressed (e.g. gzip) format.\n\n  For use-cases that differ from this common Twitter use-case,\n  further Trainer methods can be overridden.\n  If that still doesn't provide enough flexibility, the user can always\n  use the tf.estimator.Esimator or tf.session.run directly.\n  "
	def __init__(A,name,params,build_graph_fn,feature_config=None,**B):'\n    The BatchPredictionRequestTrainer constructor builds a\n    ``tf.estimator.Estimator`` and stores it in self.estimator.\n    For this reason, BatchPredictionRequestTrainer accepts the same Estimator constructor arguments.\n    It also accepts additional arguments to facilitate metric evaluation and multi-phase training\n    (init_from_dir, init_map).\n\n    Args:\n      parent arguments:\n        See the `Trainer constructor <#twml.trainers.Trainer.__init__>`_ documentation\n        for a full list of arguments accepted by the parent class.\n      name, params, build_graph_fn (and other parent class args):\n        see documentation for twml.Trainer and twml.DataRecordTrainer doc.\n      feature_config:\n        An object of type FeatureConfig describing what features to decode.\n        Defaults to None. But it is needed in the following cases:\n          - `get_train_input_fn()` / `get_eval_input_fn()` is called without a `parse_fn`\n          - `learn()`, `train()`, `eval()`, `calibrate()` are called without providing `*input_fn`.\n\n      **kwargs:\n        further kwargs can be specified and passed to the Estimator constructor.\n    ';C=A.check_batch_size_params(params);super(BatchPredictionRequestTrainer,A).__init__(name=name,params=C,build_graph_fn=build_graph_fn,**B)
	def check_batch_size_params(E,params):
		' Verify that params has the correct key,values ';D='train_batch_size';C='eval_batch_size';A=twml.util.convert_to_hparams(params);B=A.values()
		if D in B:
			if not isinstance(A.train_batch_size,int):raise ValueError('Expecting params.train_batch_size to be an integer.')
			if B[D]!=1:warnings.warn('You are processing BatchPredictionRequest data, train_batch_size is always 1.\nThe number of DataRecords in a batch is determined by the size of each BatchPredictionRequest.\nIf you did not pass train.batch_size or eval.batch_size, and the default batch_size 32 was in use,\nplease pass --train.batch_size 1 --eval.batch_size 1');A.train_batch_size=1
		if C in B:
			if not isinstance(A.train_batch_size,int):raise ValueError('Expecting params.eval_batch_size to be an integer.')
			if B[C]!=1:warnings.warn('You are processing BatchPredictionRequest data, eval_batch_size is also always 1.\nThe number of DataRecords in a batch is determined by the size of each BatchPredictionRequest.\nIf you did not pass train.batch_size or eval.batch_size, and the default batch_size 32 was in use,\nplease pass --train.batch_size 1 --eval.batch_size 1');A.eval_batch_size=1
		if C not in B:A.eval_batch_size=1
		if not A.eval_batch_size:A.eval_batch_size=1
		return A
	@staticmethod
	def add_batch_prediction_request_arguments():'\n    Add commandline args to parse typically for the BatchPredictionRequestTrainer class.\n    Typically, the user calls this function and then parses cmd-line arguments\n    into an argparse.Namespace object which is then passed to the Trainer constructor\n    via the params argument.\n\n    See the `code <_modules/twml/argument_parser.html#get_trainer_parser>`_\n    for a list and description of all cmd-line arguments.\n\n    Returns:\n      argparse.ArgumentParser instance with some useful args already added.\n    ';B='store_true';A=super(BatchPredictionRequestTrainer,BatchPredictionRequestTrainer).add_parser_arguments();A.add_argument('--model.use_existing_discretizer',action=B,dest='model_use_existing_discretizer',help='Load a pre-trained calibration or train a new one');A.add_argument('--model.use_binary_values',action=B,dest='model_use_binary_values',help='Use the use_binary_values optimization');A.add_argument('--input_size_bits',type=int,default=12,help='Number of bits allocated to the input size');A.add_argument('--loss_function',type=str,default='ranknet',dest='loss_function',help='Options are pairwise: ranknet (default), lambdarank, listnet, listmle, attrank, pointwise');A.add_argument('--use_dense_tensor',action=B,dest='use_dense_tensor',default=False,help='If use_dense_tensor is False, sparse tensor and spare normalization are in use. If use_dense_tensor is True, dense tensor and dense normalization are in use.');A.add_argument('--dense_normalization',type=str,default='mean_max_normalizaiton',dest='dense_normalization',help='Options are mean_max_normalizaiton (default), standard_normalizaiton');A.add_argument('--sparse_normalization',type=str,default='SparseMaxNorm',dest='sparse_normalization',help='Options are SparseMaxNorm (default), SparseBatchNorm');A.add_argument('--mask',type=str,default='full_mask',dest='mask',help='Options are full_mask (default), diag_mask');return A